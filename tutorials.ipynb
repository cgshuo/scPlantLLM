{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## MLM_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "project_path = '/media/workspace/caoguangshuo/scPlantLLM'\n",
    "os.chdir(f'{project_path}/s03_scPlantLLM/trainer')\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "from torch import nn\n",
    "import copy\n",
    "from loss import masked_mse_loss\n",
    "from utils import data_loader, generation_evaluate, pretrain_generation,load_config, train, evaluate, test\n",
    "import datetime\n",
    "import wandb\n",
    "sys.path.insert(0, \"../\")\n",
    "from model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "config = load_config('setting.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcgshuo\u001b[0m (\u001b[33maibio\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/workspace/caoguangshuo/scPlantGPT/s03_scPlantGPT/trainer/wandb/run-20250225_201537-g5ribq33</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aibio/test/runs/g5ribq33' target=\"_blank\">avid-sun-14</a></strong> to <a href='https://wandb.ai/aibio/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aibio/test' target=\"_blank\">https://wandb.ai/aibio/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aibio/test/runs/g5ribq33' target=\"_blank\">https://wandb.ai/aibio/test/runs/g5ribq33</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    parallel=True,\n",
    "    epochs=1, \n",
    "    batch_size=64,\n",
    "    lr=1e-4,\n",
    "    ntoken= 185622,\n",
    "    nctype= 44, \n",
    "    nbatch_effect= 238,\n",
    "    ecs_threshold=0.0, \n",
    "    layer_size=512,\n",
    "    hlayer_size=512,\n",
    "    nlayers=6,\n",
    "    nhead=8,\n",
    "    nlayers_cls=3,\n",
    "    dropout=0.5,\n",
    "    schedule_ratio=0.9, \n",
    "    save_eval_interval=5,\n",
    "    fast_transformer=True,\n",
    "    explicit_zero_prob=False,\n",
    "    pre_norm=True,\n",
    ")\n",
    "current_time = datetime.datetime.now()\n",
    "timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"test\",\n",
    "    entity=\"aibio\",\n",
    "    group=f\"{config.train_strategy}_{config.input_emb_style}\",\n",
    ")\n",
    "model_config = wandb.config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if config.input_emb_style == \"category\":\n",
    "    n_input_bins = config.n_bins + 2 # pad_value:-2, cls_value:0, masked_value:-1\n",
    "else:\n",
    "    n_input_bins = config.n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/public3/caogs/anaconda3/envs/scPlantGPT/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(185622, 512, padding_idx=0)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): CategoryValueEncoder(\n",
       "    (embedding): Embedding(103, 512, padding_idx=101)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Ara_cls_decoder): AraClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Rice_cls_decoder): RiceClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Maize_cls_decoder): MaizeClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (grad_reverse_discriminator): AdversarialDiscriminator(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=238, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    ntoken=model_config.ntoken, \n",
    "    d_model=model_config.layer_size, \n",
    "    nhead=model_config.nhead, \n",
    "    d_hid=model_config.hlayer_size,\n",
    "    nlayers=model_config.nlayers, \n",
    "    nlayers_cls=model_config.nlayers_cls, \n",
    "    n_cls=model_config.nctype, \n",
    "    dropout=model_config.dropout, \n",
    "    pad_value=int(config.pad_value),\n",
    "    pad_token_id=config.pad_token_id, \n",
    "    do_mvc=config.GEPC, \n",
    "    do_dab=True, \n",
    "    use_batch_labels=config.use_batch_labels, \n",
    "    num_batch_labels=model_config.nbatch_effect, \n",
    "    domain_spec_batchnorm=config.DSBN, \n",
    "    input_emb_style=config.input_emb_style, \n",
    "    n_input_bins= n_input_bins, \n",
    "    cell_emb_style=\"cls\", \n",
    "    mvc_decoder_style=\"inner product\", \n",
    "    ecs_threshold=model_config.ecs_threshold, \n",
    "    explicit_zero_prob=model_config.explicit_zero_prob, \n",
    "    use_fast_transformer=model_config.fast_transformer, \n",
    "    pre_norm=model_config.pre_norm,)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_path = f'{project_path}/s03_scPlantGPT/cross_data/independent_clean_label/Ara_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 182544 bytes\n"
     ]
    }
   ],
   "source": [
    "train_sampler, train_loader, trai_size=model_config.bn_metadata = data_loader(data_path, data_type='train', start_chunk=1, end_chunk=1, batch_size=model_config.batch_size, append_cls=True)\n",
    "valid_sampler, valid_loader, valid_metadata = data_loader(data_path, data_type='valid', start_chunk=1, num_chunks=1, batch_size=model_config.batch_size,append_cls=True)\n",
    "test_sampler, test_loader, test_metadata = data_loader(data_path,  data_type='test',start_chunk=1, num_chunks=1, batch_size=model_config.batch_size, append_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion_gep_gepc = masked_mse_loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=model_config.lr, eps= 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/public3/caogs/anaconda3/envs/scPlantGPT/lib/python3.11/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 145.93 | loss  2.69 | Scale Factor: 16384.0 | real loss: 2.69 | curl gep:  0.00 | mre 30823.29\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 142.69 | loss  2.13 | Scale Factor: 16384.0 | real loss: 2.13 | curl gep:  0.00 | mre 14751.19\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 143.27 | loss  2.01 | Scale Factor: 16384.0 | real loss: 2.01 | curl gep:  0.00 | mre 10807.54\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(model_config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    pretrain_generation(model, train_loader, criterion_gep_gepc, scaler, optimizer, scheduler, device, config, epoch)\n",
    "    with torch.no_grad():\n",
    "        val_loss = generation_evaluate(model, valid_loader, criterion_gep_gepc, device, config,  epoch)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "    save_path = f'./model_param/{config.train_strategy}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(save_path, f\"{timestamp}_{config.input_emb_style}_model_{epoch}.pth\")\n",
    "    # torch.save(model.module.state_dict(), checkpoint_path)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        best_model_name = f\"best_model_{config.input_emb_style}_{best_model_epoch}_{timestamp}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 69.9159927368164 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Total time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## CLS_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model_name = f\"/media/workspace/caoguangshuo/scPlantGPT/s03_scPlantGPT/trainer/model_param/scAraGPT_pretrain_clean_label_nlayer_6_mask0.15/2024Y08M17D23H15M48S_category_model_10.pth\"\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "except:\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_name)\n",
    "    pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion_gep_gepc = masked_mse_loss\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_dab = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=model_config.lr, eps=1e-4 if config.amp else 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "best_val_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | train/accuracy: 0.63625, train/error_rate: 0.37375\n",
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 152.11 | loss 81370.35 | scale factor: 65536.0 |scaled loss  1.24 |cls  1.24 | \n",
      "| epoch   0 | 200/356 batches | train/accuracy: 0.8825, train/error_rate: 0.1175\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 161.64 | loss 24675.50 | scale factor: 65536.0 |scaled loss  0.38 |cls  0.38 | \n",
      "| epoch   0 | 300/356 batches | train/accuracy: 0.91234375, train/error_rate: 0.08765625\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 173.82 | loss 18255.73 | scale factor: 65536.0 |scaled loss  0.28 |cls  0.28 | \n",
      "Epoch 0 time: 58.6326789855957\n",
      "valid/loss: 11605.9091796875, valid/cls: 0.003593619496218468, valid/accuracy: 0.9259868421052632, valid/precision: 0.8966481461133624, valid/recall: 0.8810464374992562, valid/macro_f1: 0.8876422074238292, valid/micro_f1: 0.9259868421052632\n",
      "Train time: 130.5401647090912\n",
      "Train finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(model_config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, train_loader, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config,  epoch, model_config.parallel)\n",
    "    epoch_end_time = time.time()\n",
    "    print(f\"Epoch {epoch} time: {epoch_end_time - epoch_start_time}\")\n",
    "    \n",
    "    val_loss = evaluate(model, test_loader, criterion_gep_gepc, criterion_dab, criterion_cls, device, config, epoch)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "    save_path = f'./model_param/{config.train_strategy}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(save_path, f\"{timestamp}_{config.input_emb_style}_model_{epoch}.pth\")\n",
    "    # torch.save(model.module.state_dict(), checkpoint_path)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        best_model_name = f\"best_model_{config.input_emb_style}_{best_model_epoch}_{timestamp}.pth\"\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Train time: {end_time - start_time}\")\n",
    "print(\"Train finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "celltype_vocab_path = f'{project_path}/s03_scPlantGPT/cross_data/Ara_celltype_record_clean_vocab.meta.json'\n",
    "with open(celltype_vocab_path) as f:\n",
    "        celltype_vocab = json.load(f)\n",
    "celltype_vocab = {value : key for key, value in celltype_vocab.items()} \n",
    "batch_effect_vocab_file = f'{project_path}/s03_scPlantGPT/cross_data/Ara_batch_effect_vocab.meta.json'\n",
    "with open(batch_effect_vocab_file) as f:\n",
    "        batch_effect_vocab = json.load(f)\n",
    "batch_effect_vocab  = {value : key for key, value in batch_effect_vocab.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | train/accuracy: 0.94078125, train/error_rate: 0.06921875\n",
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 192.14 | loss 14419.05 | scale factor: 65536.0 |scaled loss  0.22 |cls  0.22 | \n",
      "| epoch   0 | 200/356 batches | train/accuracy: 0.9303125, train/error_rate: 0.0696875\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 177.44 | loss 13790.64 | scale factor: 65536.0 |scaled loss  0.21 |cls  0.21 | \n",
      "| epoch   0 | 300/356 batches | train/accuracy: 0.93921875, train/error_rate: 0.06078125\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 187.89 | loss 12033.29 | scale factor: 65536.0 |scaled loss  0.18 |cls  0.18 | \n",
      "Epoch 0 time: 67.1901388168335\n",
      "valid/loss: 21615.615234375, valid/cls: 0.0025315810313546344, valid/accuracy: 0.9473684210526315, valid/precision: 0.9326877438457523, valid/recall: 0.9223693415099895, valid/macro_f1: 0.9244231323973169, valid/micro_f1: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "fine_tune = True\n",
    "if fine_tune:\n",
    "    criterion_gep_gepc = masked_mse_loss\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    criterion_dab = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=model_config.lr, eps=1e-4 if config.amp else 1e-8)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    for epoch in range(model_config.epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model, train_loader, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config,  epoch, model_config.parallel)\n",
    "            epoch_end_time = time.time()\n",
    "            print(f\"Epoch {epoch} time: {epoch_end_time - epoch_start_time}\")\n",
    "    \n",
    "            val_loss = evaluate(model, valid_loader, criterion_gep_gepc, criterion_dab, criterion_cls, device, config, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/accuracy: 0.9325657894736842, test/precision: 0.9188976906119279, test/recall: 0.8895667581705615, test/macro_f1: 0.9010580003023527, test/micro_f1: 0.9325657894736842\n",
      "Using time to predict: 3.7367961406707764\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cell_types_predictions, cell_types_labels, cell_names, probabilities, cell_embeddings, batch_labels_list = test(model, test_loader, test_metadata, device, config)\n",
    "predict_end_time = time.time()\n",
    "print(f\"Using time to predict: {predict_end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scPlantGPT",
   "language": "python",
   "name": "scplantgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
