{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## MLM_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "project_path = '/media/workspace/caoguangshuo/scPlantGPT'\n",
    "os.chdir(f'{project_path}/s03_scPlantGPT/trainer')\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "from torch import nn\n",
    "import copy\n",
    "from loss import masked_mse_loss\n",
    "from utils import data_loader, generation_evaluate, pretrain_generation,load_config, train, evaluate, test, inference\n",
    "import datetime\n",
    "import wandb\n",
    "sys.path.insert(0, \"../\")\n",
    "from scplantllm.model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "config = load_config('../Util/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcgshuo\u001b[0m (\u001b[33maibio\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/workspace/caoguangshuo/scPlantGPT/s03_scPlantGPT/trainer/wandb/run-20250314_171919-fr0jukih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aibio/test/runs/fr0jukih' target=\"_blank\">pear-pastry-17</a></strong> to <a href='https://wandb.ai/aibio/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aibio/test' target=\"_blank\">https://wandb.ai/aibio/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aibio/test/runs/fr0jukih' target=\"_blank\">https://wandb.ai/aibio/test/runs/fr0jukih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    parallel=True,\n",
    "    epochs=1, \n",
    "    batch_size=64,\n",
    "    lr=1e-4,\n",
    "    ntoken= 185622,\n",
    "    nctype= 44, \n",
    "    nbatch_effect= 238,\n",
    "    ecs_threshold=0.0, \n",
    "    layer_size=512,\n",
    "    hlayer_size=512,\n",
    "    nlayers=6,\n",
    "    nhead=8,\n",
    "    nlayers_cls=3,\n",
    "    dropout=0.5,\n",
    "    schedule_ratio=0.9, \n",
    "    save_eval_interval=5,\n",
    "    fast_transformer=True,\n",
    "    explicit_zero_prob=False,\n",
    "    pre_norm=True,\n",
    ")\n",
    "current_time = datetime.datetime.now()\n",
    "timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"test\",\n",
    "    entity=\"aibio\",\n",
    "    group=f\"{config.train_strategy}_{config.input_emb_style}\",\n",
    ")\n",
    "model_config = wandb.config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if config.input_emb_style == \"category\":\n",
    "    n_input_bins = config.n_bins + 2 # pad_value:-2, cls_value:0, masked_value:-1\n",
    "else:\n",
    "    n_input_bins = config.n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/public3/caogs/anaconda3/envs/scPlantGPT/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(185622, 512, padding_idx=0)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): CategoryValueEncoder(\n",
       "    (embedding): Embedding(103, 512, padding_idx=101)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Ara_cls_decoder): AraClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Rice_cls_decoder): RiceClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Maize_cls_decoder): MaizeClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (grad_reverse_discriminator): AdversarialDiscriminator(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=238, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(\n",
    "    ntoken=model_config.ntoken, \n",
    "    d_model=model_config.layer_size, \n",
    "    nhead=model_config.nhead, \n",
    "    d_hid=model_config.hlayer_size,\n",
    "    nlayers=model_config.nlayers, \n",
    "    nlayers_cls=model_config.nlayers_cls, \n",
    "    n_cls=model_config.nctype, \n",
    "    dropout=model_config.dropout, \n",
    "    pad_value=int(config.pad_value),\n",
    "    pad_token_id=config.pad_token_id, \n",
    "    do_mvc=config.GEPC, \n",
    "    do_dab=True, \n",
    "    use_batch_labels=config.use_batch_labels, \n",
    "    num_batch_labels=model_config.nbatch_effect, \n",
    "    domain_spec_batchnorm=config.DSBN, \n",
    "    input_emb_style=config.input_emb_style, \n",
    "    n_input_bins= n_input_bins, \n",
    "    cell_emb_style=\"cls\", \n",
    "    mvc_decoder_style=\"inner product\", \n",
    "    ecs_threshold=model_config.ecs_threshold, \n",
    "    explicit_zero_prob=model_config.explicit_zero_prob, \n",
    "    use_fast_transformer=model_config.fast_transformer, \n",
    "    pre_norm=model_config.pre_norm,)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_path = f'/public/workspace/caoguangshuo/scPlantGPT_analysis/github_test/model_data/has_celltype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Serializing object of type ndarray that is 182544 bytes\n"
     ]
    }
   ],
   "source": [
    "train_sampler, train_loader, train_size=model_config.metadata = data_loader(data_path, data_type='train', start_chunk=1, end_chunk=1, batch_size=model_config.batch_size, append_cls=True)\n",
    "valid_sampler, valid_loader, valid_metadata = data_loader(data_path, data_type='valid', start_chunk=1, num_chunks=1, batch_size=model_config.batch_size,append_cls=True)\n",
    "test_sampler, test_loader, test_metadata = data_loader(data_path,  data_type='test',start_chunk=1, num_chunks=1, batch_size=model_config.batch_size, append_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion_gep_gepc = masked_mse_loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=model_config.lr, eps= 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 133.24 | loss  1.98 | Scale Factor: 65536.0 | real loss: 1.98 | curl gep:  0.00 | mre 10245.78\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 130.44 | loss  4.01 | Scale Factor: 32768.0 | real loss: 4.01 | curl gep:  0.00 | mre 7211.55\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 130.66 | loss  1.88 | Scale Factor: 32768.0 | real loss: 1.88 | curl gep:  0.00 | mre 8512.01\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(model_config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    pretrain_generation(model, train_loader, criterion_gep_gepc, scaler, optimizer, scheduler, device, config, epoch)\n",
    "    with torch.no_grad():\n",
    "        val_loss = generation_evaluate(model, valid_loader, criterion_gep_gepc, device, config, epoch)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "    save_path = f'./model_param/{config.train_strategy}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(save_path, f\"{timestamp}_{config.input_emb_style}_model_{epoch}.pth\")\n",
    "    # torch.save(model.module.state_dict(), checkpoint_path)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        best_model_name = f\"best_model_{config.input_emb_style}_{best_model_epoch}_{timestamp}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1163.7337045669556 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Total time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## CLS_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model_name = f\"/media/workspace/caoguangshuo/scPlantGPT/s03_scPlantGPT/trainer/model_param/scAraGPT_pretrain_clean_label_nlayer_6_mask0.15/2024Y08M17D23H15M48S_category_model_10.pth\"\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "except:\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_name)\n",
    "    pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion_gep_gepc = masked_mse_loss\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_dab = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=model_config.lr, eps=1e-4 if config.amp else 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "best_val_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | train/accuracy: 0.6409375, train/error_rate: 0.3690625\n",
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 136.15 | loss 80766.91 | scale factor: 65536.0 |scaled loss  1.23 |cls  1.23 | \n",
      "| epoch   0 | 200/356 batches | train/accuracy: 0.89828125, train/error_rate: 0.10171875\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 134.10 | loss 21526.94 | scale factor: 65536.0 |scaled loss  0.33 |cls  0.33 | \n",
      "| epoch   0 | 300/356 batches | train/accuracy: 0.91671875, train/error_rate: 0.08328125\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 135.96 | loss 17929.13 | scale factor: 65536.0 |scaled loss  0.27 |cls  0.27 | \n",
      "Epoch 0 time: 48.18659210205078\n",
      "valid/loss: 7193.296875, valid/cls: 0.0037097649428209194, valid/accuracy: 0.928453947368421, valid/precision: 0.9130795682003277, valid/recall: 0.912497585510345, valid/macro_f1: 0.9098543813190176, valid/micro_f1: 0.928453947368421\n",
      "Train time: 1213.9485495090485\n",
      "Train finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(model_config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, train_loader, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config,  epoch, model_config.parallel)\n",
    "    epoch_end_time = time.time()\n",
    "    print(f\"Epoch {epoch} time: {epoch_end_time - epoch_start_time}\")\n",
    "    \n",
    "    val_loss = evaluate(model, test_loader, criterion_gep_gepc, criterion_dab, criterion_cls, device, config, epoch)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "    save_path = f'./model_param/{config.train_strategy}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(save_path, f\"{timestamp}_{config.input_emb_style}_model_{epoch}.pth\")\n",
    "    # torch.save(model.module.state_dict(), checkpoint_path)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        best_model_name = f\"best_model_{config.input_emb_style}_{best_model_epoch}_{timestamp}.pth\"\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Train time: {end_time - start_time}\")\n",
    "print(\"Train finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "celltype_vocab_path = f'{project_path}/s03_scPlantGPT/cross_data/Ara_celltype_record_clean_vocab.meta.json'\n",
    "with open(celltype_vocab_path) as f:\n",
    "        celltype_vocab = json.load(f)\n",
    "celltype_vocab = {value : key for key, value in celltype_vocab.items()} \n",
    "batch_effect_vocab_file = f'{project_path}/s03_scPlantGPT/cross_data/Ara_batch_effect_vocab.meta.json'\n",
    "with open(batch_effect_vocab_file) as f:\n",
    "        batch_effect_vocab = json.load(f)\n",
    "batch_effect_vocab  = {value : key for key, value in batch_effect_vocab.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | train/accuracy: 0.94125, train/error_rate: 0.06875\n",
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 135.85 | loss 13909.18 | scale factor: 65536.0 |scaled loss  0.21 |cls  0.21 | \n",
      "| epoch   0 | 200/356 batches | train/accuracy: 0.93953125, train/error_rate: 0.06046875\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 135.15 | loss 12491.03 | scale factor: 65536.0 |scaled loss  0.19 |cls  0.19 | \n",
      "| epoch   0 | 300/356 batches | train/accuracy: 0.940625, train/error_rate: 0.059375\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 136.78 | loss 12015.00 | scale factor: 65536.0 |scaled loss  0.18 |cls  0.18 | \n",
      "Epoch 0 time: 48.32874774932861\n",
      "valid/loss: 6326.0869140625, valid/cls: 0.0029768527846930452, valid/accuracy: 0.944078947368421, valid/precision: 0.9214912245972599, valid/recall: 0.9215046225968255, valid/macro_f1: 0.9197182795961176, valid/micro_f1: 0.944078947368421\n"
     ]
    }
   ],
   "source": [
    "fine_tune = True\n",
    "if fine_tune:\n",
    "    criterion_gep_gepc = masked_mse_loss\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    criterion_dab = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=model_config.lr, eps=1e-4 if config.amp else 1e-8)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    for epoch in range(model_config.epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model, train_loader, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config,  epoch, model_config.parallel)\n",
    "            epoch_end_time = time.time()\n",
    "            print(f\"Epoch {epoch} time: {epoch_end_time - epoch_start_time}\")\n",
    "    \n",
    "            val_loss = evaluate(model, valid_loader, criterion_gep_gepc, criterion_dab, criterion_cls, device, config, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/accuracy: 0.9407894736842105, test/precision: 0.9237605047762502, test/recall: 0.9207030126581097, test/macro_f1: 0.9209807292497322, test/micro_f1: 0.9407894736842105\n",
      "Using time to predict: 4.82179069519043\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cell_types_predictions, cell_types_labels, cell_names, probabilities, cell_embeddings, batch_labels_list = test(model, test_loader, test_metadata, device, config)\n",
    "predict_end_time = time.time()\n",
    "print(f\"Using time to predict: {predict_end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time to predict: 4.338064432144165\n",
      "[17, 29, 17, 20, 19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mpear-pastry-17\u001b[0m at: \u001b[34mhttps://wandb.ai/aibio/test/runs/fr0jukih\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250314_171919-fr0jukih/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cell_types_predictions, cell_types_labels, cell_names, probabilities, cell_embeddings, batch_labels_list = inference(model, test_loader, test_metadata, device, config)\n",
    "predict_end_time = time.time()\n",
    "print(f\"Using time to predict: {predict_end_time - start_time}\")\n",
    "print(cell_types_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scPlantGPT",
   "language": "python",
   "name": "scplantgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
